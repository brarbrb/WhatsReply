{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed98d94",
   "metadata": {},
   "source": [
    "# Imports and env  settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37234b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"cohere\" \"datasets\" \"transformers\" \"accelerate\" \"peft\" \"bitsandbytes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a7d4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, DataCollatorForLanguageModeling,Trainer\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from typing import List, Dict, Optional, Any\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import cohere\n",
    "import json\n",
    "import os\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa51a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helpers & constants from the RAG file (generated automatically from ipynb)\n",
    "from RAG_generic_func import (\n",
    "    load_and_embedd_dataset,\n",
    "    create_pinecone_index,\n",
    "    upsert_vectors,       # we'll override here\n",
    "    build_context,\n",
    "    build_user_style,     # same\n",
    "    augment_prompt,\n",
    "    EMBEDDING_MODEL,\n",
    "    COHERE_API_KEY,\n",
    "    PINECONE_API_KEY,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a9ba9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = os.environ.get(\"COHERE_API_KEY_PAY\", \"\")\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\", \"\")\n",
    "\n",
    "INPUT_PATH_TRAIN = r\"C:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\Fine_Tune\\fine_tune_data\\bbt_train_cleaned.jsonl\"\n",
    "INPUT_PATH_VAL   = r\"C:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\Fine_Tune\\fine_tune_data\\bbt_val_cleaned.jsonl\"\n",
    "\n",
    "OUTPUT_PATH_TRAIN = r\"C:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\Fine_Tune\\fine_tune_data\\bbt_train_distilled.jsonl\"\n",
    "OUTPUT_PATH_VAL   = r\"C:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\Fine_Tune\\fine_tune_data\\bbt_val_distilled.jsonl\"\n",
    "\n",
    "MODEL_OUTPUT_PATH = r\"C:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\Fine_Tune\\distilled\"\n",
    "data_files = {\n",
    "    \"train\": OUTPUT_PATH_TRAIN,\n",
    "    \"validation\": OUTPUT_PATH_VAL\n",
    "}\n",
    "# ds = load_dataset(\"json\", data_files=data_files)\n",
    "# TARGET_MODULES = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"] # full attention\n",
    "TARGET_MODULES = [\"q_proj\",\"v_proj\"]\n",
    "\n",
    "\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "KB_PATH = r\"RAG_data\\KB_data.csv\"\n",
    "OUTPUT_KB_JSONL = r\"RAG_data\\distillation_dataset.jsonl\"\n",
    "\n",
    "AUGMENT_FRACTION = 0.3   # fraction of human examples that also get a teacher-label version\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "USER = \"Barbara\"         # change if your Barbara user_id is different\n",
    "INDEX_NAME = \"chats-index\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227ad3f2",
   "metadata": {},
   "source": [
    "# Distillation to improve fine-tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7b2a0",
   "metadata": {},
   "source": [
    "## Preparing the distilled dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299648e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.ClientV2(COHERE_API_KEY)\n",
    "\n",
    "# Simple persona descriptions per speaker\n",
    "PERSONAS = {\n",
    "    \"Sheldon\": (\n",
    "        \"You are Sheldon Cooper from The Big Bang Theory. \"\n",
    "        \"You are a brilliant, pedantic theoretical physicist: literal, arrogant, and verbose. \"\n",
    "        \"You speak in precise, formal, slightly condescending language and often reference science, physics, and your own intellect.\"\n",
    "    ),\n",
    "    \"Leonard\": (\n",
    "        \"You are Leonard Hofstadter from The Big Bang Theory. \"\n",
    "        \"You are kind, self-conscious, often nervous, and try to keep the peace between your friends. \"\n",
    "        \"You speak in a casual, slightly awkward but caring tone, and you often try to sound reasonable and supportive.\"\n",
    "    ),\n",
    "    \"Penny\": (\n",
    "        \"You are Penny from The Big Bang Theory. \"\n",
    "        \"You are friendly, sarcastic, and down-to-earth, with good social intuition. \"\n",
    "        \"You use casual everyday language, sometimes tease the guys, and react emotionally and humorously to their geeky behavior.\"\n",
    "    ),\n",
    "    \"Howard\": (\n",
    "        \"You are Howard Wolowitz from The Big Bang Theory. \"\n",
    "        \"You are an aerospace engineer with an overconfident, sometimes creepy flirtatious style. \"\n",
    "        \"You crack innuendo-filled jokes, brag about your accomplishments, and speak in a playful, comedic tone, especially about space and women.\"\n",
    "    ),\n",
    "    \"Raj\": (\n",
    "        \"You are Rajesh Koothrappali from The Big Bang Theory. \"\n",
    "        \"You are sensitive, romantic, and somewhat socially awkward, with a love of pop culture and fantasy. \"\n",
    "        \"You speak in an emotional, sometimes dramatic way, and you often talk about love, loneliness, and your interests like movies and comics.\"\n",
    "    ),\n",
    "    \"Amy\": (\n",
    "        \"You are Amy Farrah Fowler from The Big Bang Theory. \"\n",
    "        \"You are a neurobiologist with a mix of scientific seriousness and socially awkward earnestness. \"\n",
    "        \"You speak in a formal, analytical tone about emotions and relationships, and you are intensely devoted to Sheldon and your friends.\"\n",
    "    ),\n",
    "    \"Bernadette\": (\n",
    "        \"You are Bernadette Rostenkowski-Wolowitz from The Big Bang Theory. \"\n",
    "        \"You have a sweet, high-pitched speaking style that can turn surprisingly strict or intimidating. \"\n",
    "        \"You are practical, sometimes bossy, and you often mix cute phrasing with sharp, no-nonsense comments.\"\n",
    "    ),\n",
    "    # other non-central charactes\n",
    "    \"DEFAULT\": (\n",
    "        \"You are a character from The Big Bang Theory. \"\n",
    "        \"Respond in a style consistent with that character's personality and the show's comedic tone.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "def get_persona(speaker: str) -> str:\n",
    "    if not speaker:\n",
    "        return PERSONAS[\"DEFAULT\"]\n",
    "    return PERSONAS.get(speaker, PERSONAS[\"DEFAULT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d2d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distil_file(input_path: str, output_path: str, max_examples: int | None = None):\n",
    "    \"\"\"Reads original BBT JSONL and translates to teacher_target using Cohere\"\"\"\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as fin:\n",
    "        lines = [json.loads(l) for l in fin]\n",
    "\n",
    "    if max_examples is not None:\n",
    "        lines = lines[:max_examples]\n",
    "\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "        for ex in tqdm(lines, desc=f\"Distilling {input_path}\"):\n",
    "            prompt = ex.get(\"prompt\", \"\")\n",
    "            target_speaker = ex.get(\"target_speaker\", \"\")\n",
    "\n",
    "            persona = get_persona(target_speaker)\n",
    "\n",
    "            # We use Cohere chat endpoint with system + user message\n",
    "            try:\n",
    "                response = co.chat(\n",
    "                    model=\"command-a-03-2025\",\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": (\n",
    "                                persona\n",
    "                                + \" You will be given the dialogue context. \"\n",
    "                                  \"Continue the next line exactly as this character would speak. \"\n",
    "                                  \"Respond with ONLY the next line of dialogue, no quotes, \"\n",
    "                                  \"and do NOT add speaker tags.\"\n",
    "                            ),\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": prompt,\n",
    "                        },\n",
    "                    ],\n",
    "                    temperature=0.7,\n",
    "                    max_tokens=96,\n",
    "                )\n",
    "                teacher_text = response.message.content[0].text.strip()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error on example with ep={ex.get('ep')} scene={ex.get('scene')}:\", e)\n",
    "                # if Cohere fails we just use original script target \n",
    "                teacher_text = ex.get(\"target\", \"\").strip()\n",
    "\n",
    "            ex[\"teacher_target\"] = teacher_text\n",
    "\n",
    "            fout.write(json.dumps(ex, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "distil_file(INPUT_PATH_TRAIN, OUTPUT_PATH_TRAIN, max_examples=None) # meaning all - depends on restrictions of cohere account\n",
    "distil_file(INPUT_PATH_VAL, OUTPUT_PATH_VAL, max_examples=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6239ea9",
   "metadata": {},
   "source": [
    "## Running fine tune again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0014fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "output_dir = r\"Fine_Tune\\outputs\\tinyllama_bbt_distilled_lora\"\n",
    "\n",
    "ds = load_dataset(\"json\", data_files=data_files)\n",
    "train_ds = ds[\"train\"]\n",
    "val_ds = ds[\"validation\"]\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(model_id)\n",
    "if tok.pad_token is None:\n",
    "    tok.pad_token = tok.eos_token\n",
    "\n",
    "base = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    ")\n",
    "\n",
    "base.config.pad_token_id = tok.pad_token_id\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=TARGET_MODULES,\n",
    ")\n",
    "\n",
    "model = get_peft_model(base, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe33f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 512\n",
    "\n",
    "def build_example(ex):\n",
    "    prompt = ex.get(\"prompt\", \"\")\n",
    "    # Use teacher's answer as label (distillation)\n",
    "    target = ex.get(\"teacher_target\", ex.get(\"target\", \"\"))\n",
    "    x = prompt + target\n",
    "\n",
    "    enc_full   = tok(x, max_length=max_len, truncation=True)\n",
    "    enc_prompt = tok(prompt, max_length=max_len, truncation=True)\n",
    "\n",
    "    input_ids = enc_full[\"input_ids\"]\n",
    "    labels    = input_ids.copy()\n",
    "\n",
    "    # mask prompt part\n",
    "    n_prompt = len(enc_prompt[\"input_ids\"])\n",
    "    for i in range(min(n_prompt, len(labels))):\n",
    "        labels[i] = -100\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": enc_full[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "\n",
    "train_tok = train_ds.map(\n",
    "    build_example,\n",
    "    remove_columns=train_ds.column_names,\n",
    ")\n",
    "val_tok = val_ds.map(\n",
    "    build_example,\n",
    "    remove_columns=val_ds.column_names,\n",
    ")\n",
    "\n",
    "train_tok.set_format(type=\"torch\", columns=cols)\n",
    "val_tok.set_format(type=\"torch\", columns=cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f069f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't want random masking (MLM); we already prepared labels ourselves.\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tok,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    warmup_ratio=0.03,\n",
    "    fp16=True,           # if GPU supports it\n",
    "    bf16=False,          #  True if on A100\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(output_dir)\n",
    "tok.save_pretrained(output_dir)\n",
    "print(\"Finished training + saved model + tokenizer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b9bb1b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e244f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30d5d4db",
   "metadata": {},
   "source": [
    "# Distillation on actual chats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb88098",
   "metadata": {},
   "source": [
    "## Getting teacher labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f7f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_style(\n",
    "    df: pd.DataFrame,\n",
    "    user_id: str,\n",
    "    k: int = 10,\n",
    "    text_col: str = \"text\",\n",
    "    random_sample: bool = True,\n",
    "    seed: int | None = 42,\n",
    ") -> tuple[list[str], str]:\n",
    "    \"\"\"\n",
    "    Return:\n",
    "      - list of example messages (lines)\n",
    "      - a single multi-line string user_style\n",
    "\n",
    "    If there are no messages for this user_id, returns ([], \"\").\n",
    "    \"\"\"\n",
    "    user_df = df[df[\"sender_user_id\"] == user_id].copy()\n",
    "\n",
    "    if len(user_df) == 0:\n",
    "        return [], \"\"\n",
    "\n",
    "    user_df = user_df.sort_values(\"sent_at\")\n",
    "\n",
    "    if random_sample and len(user_df) > k:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        idx = rng.choice(user_df.index.to_list(), size=k, replace=False)\n",
    "        user_df = user_df.loc[idx].sort_values(\"sent_at\")\n",
    "    else:\n",
    "        user_df = user_df.tail(k)\n",
    "\n",
    "    lines = [str(msg) for msg in user_df[text_col].tolist()]\n",
    "    user_style = \"\\n\".join(lines)\n",
    "    return lines, user_style\n",
    "\n",
    "\n",
    "def upsert_vectors(\n",
    "    index,               # Pinecone index object\n",
    "    dataset: pd.DataFrame,\n",
    "    embeddings: np.ndarray,\n",
    "    batch_size: int = 128,\n",
    "):\n",
    "    \"\"\"\n",
    "    Upsert vectors to a Pinecone index.\n",
    "\n",
    "    Args:\n",
    "        index: pc.Index instance.\n",
    "        dataset: DataFrame containing metadata; must align with embeddings.\n",
    "        embeddings: numpy array [n_rows, dim].\n",
    "    \"\"\"\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    print(\"Upserting the embeddings to the Pinecone index...\")\n",
    "\n",
    "    if embeddings.shape[0] != len(dataset):\n",
    "        raise ValueError(\n",
    "            f\"Embeddings rows ({embeddings.shape[0]}) != dataset rows ({len(dataset)})\"\n",
    "        )\n",
    "\n",
    "    metadata_fields = [col for col in dataset.columns if col != \"embedding\"]\n",
    "\n",
    "    num_rows = embeddings.shape[0]\n",
    "    ids = [str(i) for i in range(num_rows)]\n",
    "\n",
    "    meta = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        entry = {col: row[col] for col in metadata_fields}\n",
    "        meta.append(entry)\n",
    "\n",
    "    to_upsert = list(zip(ids, embeddings, meta))\n",
    "\n",
    "    for i in tqdm(range(0, len(to_upsert), batch_size)):\n",
    "        i_end = min(i + batch_size, len(to_upsert))\n",
    "        index.upsert(vectors=to_upsert[i:i_end])\n",
    "\n",
    "    print(\"Upserting complete!\")\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45ff9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RAG initialization ===\n",
      "Loading and embedding the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a70a1ae9db4c2d9cd189055997af01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Rows for Barbara as receiver: 1181\n",
      "Creating a Pinecone index...\n",
      "Done!\n",
      "Upserting the embeddings to the Pinecone index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:36<00:00,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting complete!\n",
      "RAG initialization done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== RAG initialization ===\")\n",
    "\n",
    "# Cohere client\n",
    "co = cohere.Client(api_key=COHERE_API_KEY)\n",
    "\n",
    "# 1) Load KB\n",
    "whatsapp_chats = pd.read_csv(KB_PATH)\n",
    "\n",
    "# 2) Embed entire KB once\n",
    "model_emb = SentenceTransformer(EMBEDDING_MODEL)\n",
    "kb_df_all, embeddings = load_and_embedd_dataset(whatsapp_chats, model_emb)\n",
    "\n",
    "# 3) Keep only rows where Barbara is the receiver (for retrieval)\n",
    "kb_df_to_barbara = kb_df_all[kb_df_all[\"receiver_user_id\"] == USER].sort_values(\"conv_turn\")\n",
    "embeddings_to_barbara = embeddings[kb_df_to_barbara.index.to_list()]\n",
    "\n",
    "print(\"Rows for Barbara as receiver:\", len(kb_df_to_barbara))\n",
    "\n",
    "# 4) Create Pinecone index once\n",
    "pc = create_pinecone_index(INDEX_NAME, embeddings_to_barbara.shape[1])\n",
    "\n",
    "# 5) Upsert embeddings once\n",
    "index = pc.Index(INDEX_NAME)\n",
    "index = upsert_vectors(index, kb_df_to_barbara, embeddings_to_barbara)\n",
    "\n",
    "# 6) Shared context & style for Barbara (can tune conv_id)\n",
    "context = build_context(\n",
    "    kb_df_all,\n",
    "    conv_id=\"chat:u_1_u_2\",  # adjust conv_id as needed\n",
    "    k=10,\n",
    ")\n",
    "\n",
    "_, user_style = build_user_style(\n",
    "    kb_df_all,\n",
    "    user_id=USER,\n",
    "    k=10,\n",
    ")\n",
    "\n",
    "print(\"RAG initialization done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adeef431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohere_rag_answer(query: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Use cached embeddings + Pinecone index + user_style + context\n",
    "    to get a Cohere+RAG answer for a query.\n",
    "\n",
    "    Returns None if something fails.\n",
    "    \"\"\"\n",
    "    query = str(query).strip()\n",
    "    if not query:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        augmented_prompt, _ = augment_prompt(\n",
    "            query=query,\n",
    "            user_style=user_style,\n",
    "            context=context,\n",
    "            model=model_emb,\n",
    "            index=index,\n",
    "        )\n",
    "\n",
    "        response = co.chat(\n",
    "            model=\"command-a-03-2025\",\n",
    "            message=augmented_prompt,\n",
    "        )\n",
    "        text = response.text.strip()\n",
    "        if not text:\n",
    "            return None\n",
    "        return text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Cohere failed for query: {query[:60]!r}... ({e})\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def generate_teacher_answer(query: str, kb_path: str = KB_PATH) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Wrapper used by the dataset builder.\n",
    "    Now uses the cached RAG state instead of re-embedding each time.\n",
    "    \"\"\"\n",
    "    return cohere_rag_answer(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b726ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_input_text(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Build the text that will go into the student model.\n",
    "    For now it's simple; later you can plug in full RAG context, etc.\n",
    "    \"\"\"\n",
    "    query = str(row[\"text\"]).strip()\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are {USER}. Answer in her natural WhatsApp style.\\n\\n\"\n",
    "        \"### QUERY\\n\"\n",
    "        f\"{query}\\n\\n\"\n",
    "        \"### INSTRUCTIONS\\n\"\n",
    "        f\"Reply as {USER} would reply in WhatsApp.\"\n",
    "    )\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e60e399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in KB: 2360\n",
      "Rows with receiver == 'Barbara' and non-empty human answer: 1181\n",
      "Base human examples: 1181\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(KB_PATH)\n",
    "\n",
    "df[\"answer\"] = df[\"answer\"].astype(str)\n",
    "mask_receiver_barbara = df[\"receiver_user_id\"] == USER\n",
    "\n",
    "# rows with non-empty human answer\n",
    "mask_has_human = df[\"answer\"].str.strip().ne(\"\")\n",
    "human_df = df[mask_receiver_barbara & mask_has_human].copy()\n",
    "print(f\"Total rows in KB: {len(df)}\")\n",
    "print(f\"Rows with receiver == {USER!r} and non-empty human answer: {len(human_df)}\")\n",
    "\n",
    "examples: List[Dict[str, Any]] = []\n",
    "for _, row in human_df.iterrows():\n",
    "    input_text = build_input_text(row)\n",
    "    human_answer = row[\"answer\"].strip()\n",
    "\n",
    "    examples.append({\n",
    "        \"input_text\": input_text,\n",
    "        \"target_text\": human_answer,\n",
    "        \"label_source\": \"human\",   # used later for sampling/weighting\n",
    "    })\n",
    "\n",
    "print(f\"Base human examples: {len(examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3822fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will augment 354 rows with teacher answers\n",
      "Total examples after adding teacher labels: 1535\n"
     ]
    }
   ],
   "source": [
    "# randomly sampling rows where we add teacher\n",
    "indices = list(human_df.index)\n",
    "n_aug = int(AUGMENT_FRACTION * len(indices))\n",
    "augment_indices = set(random.sample(indices, n_aug))\n",
    "print(f\"Will augment {n_aug} rows with teacher answers\")\n",
    "\n",
    "for idx in augment_indices:\n",
    "    row = human_df.loc[idx]\n",
    "    query = str(row[\"text\"]).strip()\n",
    "    input_text = build_input_text(row)\n",
    "\n",
    "    teacher_answer = generate_teacher_answer(query)\n",
    "    if teacher_answer is None:\n",
    "        print(\"Haven't generated answer\")\n",
    "        continue\n",
    "\n",
    "    examples.append({\n",
    "        \"input_text\": input_text,\n",
    "        \"target_text\": teacher_answer,\n",
    "        \"label_source\": \"teacher\",\n",
    "    })\n",
    "    \n",
    "print(f\"Total examples after adding teacher labels: {len(examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "040c3c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distillation dataset to RAG_data\\distillation_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "out_df = pd.DataFrame(examples)\n",
    "out_df.to_json(\n",
    "    OUTPUT_KB_JSONL,\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    "    force_ascii=False,\n",
    ")\n",
    "print(f\"Saved distillation dataset to {OUTPUT_KB_JSONL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_query_from_input(input_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the text between '### QUERY' and '\\\\n\\\\n### INSTRUCTIONS'\n",
    "    from the input_text. Returns an empty string if pattern not found.\n",
    "    \"\"\"\n",
    "    if not isinstance(input_text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    marker_query = \"### QUERY\"\n",
    "    marker_instr = \"\\n\\n### INSTRUCTIONS\"\n",
    "    \n",
    "    pos_q = input_text.find(marker_query)\n",
    "    if pos_q == -1:\n",
    "        return \"\"\n",
    "    \n",
    "    # start after the line \"### QUERY\\n\"\n",
    "    pos_start = input_text.find(\"\\n\", pos_q)\n",
    "    if pos_start == -1:\n",
    "        return \"\"\n",
    "    pos_start += 1  # move past the newline\n",
    "    \n",
    "    pos_end = input_text.find(marker_instr, pos_start)\n",
    "    if pos_end == -1:\n",
    "        # take until the end if instructions marker not found\n",
    "        pos_end = len(input_text)\n",
    "    \n",
    "    query = input_text[pos_start:pos_end]\n",
    "    return query.strip()\n",
    "\n",
    "\n",
    "def cohere_barbara_reply(query: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Ask Cohere to answer as Barbara in WhatsApp style given just the query.\n",
    "    No RAG here – quick cleaning only.\n",
    "    \"\"\"\n",
    "    query = str(query).strip()\n",
    "    if not query:\n",
    "        return None\n",
    "    \n",
    "    prompt = (\n",
    "        \"You are Barbara. Answer in her natural WhatsApp style.\\n\\n\"\n",
    "        \"### QUERY\\n\"\n",
    "        f\"{query}\\n\\n\"\n",
    "        \"### INSTRUCTIONS\\n\"\n",
    "        \"Reply as Barbara would reply in WhatsApp. Use natural, short WhatsApp-style messages, \"\n",
    "        \"can include line breaks and emojis. Only output the reply, no explanations.\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        resp = co.chat(\n",
    "            model=\"command-r-08-2024\",\n",
    "            message=prompt,\n",
    "        )\n",
    "        text = resp.text.strip()\n",
    "        if not text:\n",
    "            return None\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Cohere failed for query: {query[:60]!r}... ({e})\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d662f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(OUTPUT_KB_JSONL, lines=True)\n",
    "print(\"Original rows:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36299e",
   "metadata": {},
   "source": [
    "## Getting teacher labels - old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39924b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: build the input text for the student\n",
    "def build_input_text(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Build the text that will go into the student model.\n",
    "    simple query + instructions.\n",
    "    \"\"\"\n",
    "    query = str(row[\"text\"]).strip()\n",
    "\n",
    "    prompt = (\n",
    "        \"You are Barbara. Answer in her natural WhatsApp style.\\n\\n\"\n",
    "        \"### QUERY\\n\"\n",
    "        f\"{query}\\n\\n\"\n",
    "        \"### INSTRUCTIONS\\n\"\n",
    "        \"Reply as Barbara would reply in WhatsApp.\"\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a1caec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets a teacher answer\n",
    "def generate_teacher_answer(query: str, kb_path: str = KB_PATH) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Wraps the existing RAG pipeline.\n",
    "    This function returns the teacher's text reply as a string.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        teacher_reply = rag_pipleine(kb_path, query)\n",
    "        if teacher_reply is None:\n",
    "            return None\n",
    "        teacher_reply = str(teacher_reply).strip()\n",
    "        if not teacher_reply:\n",
    "            return None\n",
    "        return teacher_reply\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Teacher generation failed for query: {query[:60]!r}... ({e})\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262f531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in KB: 2360\n",
      "Rows with receiver == 'Barbara' and non-empty human answer: 1181\n"
     ]
    }
   ],
   "source": [
    "# Building the mixed human+teacher dataset\n",
    "df = pd.read_csv(KB_PATH)\n",
    "\n",
    "df[\"answer\"] = df[\"answer\"].astype(str)\n",
    "\n",
    "USER = \"Barbara\"  # user whose tone we imitate\n",
    "mask_receiver_barbara = df[\"receiver_user_id\"] == USER\n",
    "mask_has_human = df[\"answer\"].str.strip().ne(\"\")\n",
    "\n",
    "human_df = df[mask_receiver_barbara & mask_has_human].copy()\n",
    "\n",
    "print(f\"Total rows in KB: {len(df)}\")\n",
    "print(f\"Rows with receiver == {USER!r} and non-empty human answer: {len(human_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8fc9d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base human examples: 1181\n"
     ]
    }
   ],
   "source": [
    "# Building base list of examples (always 1 human example per row)\n",
    "examples: List[Dict] = []\n",
    "\n",
    "for _, row in human_df.iterrows():\n",
    "    input_text = build_input_text(row)\n",
    "    human_answer = row[\"answer\"].strip()\n",
    "    examples.append({\n",
    "        \"input_text\": input_text,\n",
    "        \"target_text\": human_answer,\n",
    "        \"label_source\": \"human\",   # we’ll use this later for sampling\n",
    "    })\n",
    "print(f\"Base human examples: {len(examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a10e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will augment 354 rows with teacher answers\n"
     ]
    }
   ],
   "source": [
    "# randomly sampling rows that get additional teacher labels\n",
    "indices = list(human_df.index)\n",
    "n_aug = int(AUGMENT_FRACTION * len(indices))\n",
    "augment_indices = set(random.sample(indices, n_aug))\n",
    "print(f\"Will augment {n_aug} rows with teacher answers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80285a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and embedding the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b6e8e65b284746acabc2ece6bde557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Creating a Pinecone index...\n",
      "Done!\n",
      "Upserting the embeddings to the Pinecone index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:35<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting complete!\n",
      "Loading and embedding the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d7607fb7cd4326bbd1a01da974f698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Creating a Pinecone index...\n",
      "Done!\n",
      "Upserting the embeddings to the Pinecone index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:40<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting complete!\n",
      "Loading and embedding the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15707702ea5d4c2ea89dc9c637f90e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Creating a Pinecone index...\n",
      "Done!\n",
      "Upserting the embeddings to the Pinecone index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:37<00:00,  3.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting complete!\n",
      "Loading and embedding the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8aec150c444864bc0b61b76af64e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Creating a Pinecone index...\n",
      "Done!\n",
      "Upserting the embeddings to the Pinecone index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:38<00:00,  3.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting complete!\n",
      "Loading and embedding the dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3058dca3adb4579a27eed541b37d89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Creating a Pinecone index...\n",
      "Done!\n",
      "Upserting the embeddings to the Pinecone index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:41<00:00,  4.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserting complete!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m query = \u001b[38;5;28mstr\u001b[39m(row[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]).strip()\n\u001b[32m      5\u001b[39m input_text = build_input_text(row)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m teacher_answer = \u001b[43mgenerate_teacher_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m teacher_answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mgenerate_teacher_answer\u001b[39m\u001b[34m(query, kb_path)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mWraps the existing RAG pipeline.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mThis function returns the teacher's text reply as a string.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     teacher_reply = \u001b[43mrag_pipleine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkb_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m teacher_reply \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     10\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\RAG\\RAG_generic_func.py:363\u001b[39m, in \u001b[36mrag_pipleine\u001b[39m\u001b[34m(kb_knoloedge_path, query)\u001b[39m\n\u001b[32m    355\u001b[39m barbara_messages, user_style = build_user_style(\n\u001b[32m    356\u001b[39m     kb_df_all,\n\u001b[32m    357\u001b[39m     user_id=\u001b[33m\"\u001b[39m\u001b[33mBarbara\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    358\u001b[39m     k=\u001b[32m10\u001b[39m,\n\u001b[32m    359\u001b[39m )\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# query = \"i need help with my students, did you taught them already the embeddings ppt?\"\u001b[39;00m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# Augment the prompt with retrieved context\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m augmented_prompt, source_knowledge = \u001b[43maugment_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_style\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_style\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_emb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_upserted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m#Cohere\u001b[39;00m\n\u001b[32m    372\u001b[39m co = cohere.Client(api_key=COHERE_API_KEY)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\RAG\\RAG_generic_func.py:258\u001b[39m, in \u001b[36maugment_prompt\u001b[39m\u001b[34m(query, user_style, context, model, index)\u001b[39m\n\u001b[32m    255\u001b[39m results = [\u001b[38;5;28mfloat\u001b[39m(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(model.encode(query))]\n\u001b[32m    257\u001b[39m \u001b[38;5;66;03m# get top 10 results from knowledge base\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m query_results = \u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_values\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    260\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mmatches\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    261\u001b[39m text_matches = [match[\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m query_results]\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# get the text from the results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\utils\\error_handling.py:27\u001b[39m, in \u001b[36mvalidate_and_convert_errors.<locals>.inner_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner_func\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> R:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     29\u001b[39m         \u001b[38;5;66;03m# Lazy import of urllib3 exceptions\u001b[39;00m\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaxRetryError, ProtocolError \u001b[38;5;28;01mas\u001b[39;00m Urllib3ProtocolError\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\db_data\\index.py:1083\u001b[39m, in \u001b[36mIndex.query\u001b[39m\u001b[34m(self, top_k, vector, id, namespace, filter, include_values, include_metadata, sparse_vector, *args, **kwargs)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;129m@validate_and_convert_errors\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\n\u001b[32m    995\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1005\u001b[39m     **kwargs,\n\u001b[32m   1006\u001b[39m ) -> QueryResponse | ApplyResult:\n\u001b[32m   1007\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Query a namespace using a query vector.\u001b[39;00m\n\u001b[32m   1008\u001b[39m \n\u001b[32m   1009\u001b[39m \u001b[33;03m    The Query operation searches a namespace, using a query vector.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1081\u001b[39m \n\u001b[32m   1082\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43msparse_vector\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparse_vector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33masync_req\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs.get(\u001b[33m\"\u001b[39m\u001b[33masync_threadpool_executor\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1097\u001b[39m         \u001b[38;5;66;03m# For async requests, the OpenAPI client wraps the response in ApplyResult\u001b[39;00m\n\u001b[32m   1098\u001b[39m         \u001b[38;5;66;03m# The response is already an ApplyResult[OpenAPIQueryResponse]\u001b[39;00m\n\u001b[32m   1099\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response  \u001b[38;5;66;03m# type: ignore[return-value]  # ApplyResult is not tracked through OpenAPI layers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\db_data\\index.py:1137\u001b[39m, in \u001b[36mIndex._query\u001b[39m\u001b[34m(self, top_k, vector, id, namespace, filter, include_values, include_metadata, sparse_vector, *args, **kwargs)\u001b[39m\n\u001b[32m   1124\u001b[39m request = IndexRequestFactory.query_request(\n\u001b[32m   1125\u001b[39m     top_k=top_k,\n\u001b[32m   1126\u001b[39m     vector=vector,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1133\u001b[39m     **kwargs,\n\u001b[32m   1134\u001b[39m )\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cast\n\u001b[32m-> \u001b[39m\u001b[32m1137\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vector_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_vectors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_openapi_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[38;5;66;03m# When async_req=False, result is QueryResponse, not ApplyResult\u001b[39;00m\n\u001b[32m   1139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(OpenAPIQueryResponse, result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\openapi_support\\endpoint.py:102\u001b[39m, in \u001b[36mEndpoint.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     92\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"This method is invoked when endpoints are called\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m     94\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m \n\u001b[32m    101\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\core\\openapi\\db_data\\api\\vector_operations_api.py:548\u001b[39m, in \u001b[36mVectorOperationsApi.__init__.<locals>.__query_vectors\u001b[39m\u001b[34m(self, query_request, x_pinecone_api_version, **kwargs)\u001b[39m\n\u001b[32m    545\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mx_pinecone_api_version\u001b[39m\u001b[33m\"\u001b[39m] = x_pinecone_api_version\n\u001b[32m    546\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mquery_request\u001b[39m\u001b[33m\"\u001b[39m] = query_request\n\u001b[32m    547\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m     QueryResponse | ApplyResult[QueryResponse], \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    549\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\openapi_support\\endpoint.py:134\u001b[39m, in \u001b[36mEndpoint.call_with_http_info\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    124\u001b[39m params = EndpointUtils.gather_params(\n\u001b[32m    125\u001b[39m     attribute_map=\u001b[38;5;28mself\u001b[39m.attribute_map,\n\u001b[32m    126\u001b[39m     location_map=\u001b[38;5;28mself\u001b[39m.location_map,\n\u001b[32m   (...)\u001b[39m\u001b[32m    129\u001b[39m     kwargs=kwargs,\n\u001b[32m    130\u001b[39m )\n\u001b[32m    132\u001b[39m HeaderUtil.prepare_headers(headers_map=\u001b[38;5;28mself\u001b[39m.headers_map, params=params)\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mendpoint_path\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttp_method\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mheader\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbody\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43masync_req\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43masync_threadpool_executor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43masync_threadpool_executor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_check_return_type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_return_http_data_only\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_preload_content\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_request_timeout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcollection_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:320\u001b[39m, in \u001b[36mApiClient.call_api\u001b[39m\u001b[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, async_threadpool_executor, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[39m\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.threadpool_executor.submit(\n\u001b[32m    300\u001b[39m         \u001b[38;5;28mself\u001b[39m.__call_api,\n\u001b[32m    301\u001b[39m         resource_path,\n\u001b[32m   (...)\u001b[39m\u001b[32m    316\u001b[39m         _check_type,\n\u001b[32m    317\u001b[39m     )\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_check_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pool.apply_async(\n\u001b[32m    340\u001b[39m     \u001b[38;5;28mself\u001b[39m.__call_api,\n\u001b[32m    341\u001b[39m     (\n\u001b[32m   (...)\u001b[39m\u001b[32m    358\u001b[39m     ),\n\u001b[32m    359\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:173\u001b[39m, in \u001b[36mApiClient.__call_api\u001b[39m\u001b[34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[39m\n\u001b[32m    164\u001b[39m url = build_request_url(\n\u001b[32m    165\u001b[39m     config=config,\n\u001b[32m    166\u001b[39m     processed_path_params=path_params_tuple,\n\u001b[32m    167\u001b[39m     resource_path=resource_path,\n\u001b[32m    168\u001b[39m     _host=_host,\n\u001b[32m    169\u001b[39m )\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     response_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessed_query_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessed_post_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    184\u001b[39m     e.body = e.body.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\openapi_support\\api_client.py:400\u001b[39m, in \u001b[36mApiClient.request\u001b[39m\u001b[34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rest_client.OPTIONS(\n\u001b[32m    391\u001b[39m         url,\n\u001b[32m    392\u001b[39m         query_params=query_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m         body=body,\n\u001b[32m    398\u001b[39m     )\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrest_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPOST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"\u001b[39m\u001b[33mPUT\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rest_client.PUT(\n\u001b[32m    411\u001b[39m         url,\n\u001b[32m    412\u001b[39m         query_params=query_params,\n\u001b[32m   (...)\u001b[39m\u001b[32m    417\u001b[39m         body=body,\n\u001b[32m    418\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\openapi_support\\rest_utils.py:146\u001b[39m, in \u001b[36mRestClientInterface.POST\u001b[39m\u001b[34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mPOST\u001b[39m(\n\u001b[32m    137\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    138\u001b[39m     url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    144\u001b[39m     _request_timeout=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    145\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pinecone\\openapi_support\\rest_urllib3.py:193\u001b[39m, in \u001b[36mUrllib3RestClient.request\u001b[39m\u001b[34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[39m\n\u001b[32m    191\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# content_type == \"application/json\":\u001b[39;00m\n\u001b[32m    192\u001b[39m             request_body = orjson.dumps(body).decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m content_type == \u001b[33m\"\u001b[39m\u001b[33mapplication/x-www-form-urlencoded\u001b[39m\u001b[33m\"\u001b[39m:  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m    203\u001b[39m     r = \u001b[38;5;28mself\u001b[39m.pool_manager.request(\n\u001b[32m    204\u001b[39m         method,\n\u001b[32m    205\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    210\u001b[39m         headers=headers,\n\u001b[32m    211\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\urllib3\\_request_methods.py:143\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_url(\n\u001b[32m    136\u001b[39m         method,\n\u001b[32m    137\u001b[39m         url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m         **urlopen_kw,\n\u001b[32m    141\u001b[39m     )\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43murlopen_kw\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\urllib3\\_request_methods.py:278\u001b[39m, in \u001b[36mRequestMethods.request_encode_body\u001b[39m\u001b[34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[39m\n\u001b[32m    274\u001b[39m     extra_kw[\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m].setdefault(\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m, content_type)\n\u001b[32m    276\u001b[39m extra_kw.update(urlopen_kw)\n\u001b[32m--> \u001b[39m\u001b[32m278\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\urllib3\\poolmanager.py:459\u001b[39m, in \u001b[36mPoolManager.urlopen\u001b[39m\u001b[34m(self, method, url, redirect, **kw)\u001b[39m\n\u001b[32m    457\u001b[39m     response = conn.urlopen(method, url, **kw)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# adding teacher examples for selected rows\n",
    "for idx in augment_indices:\n",
    "    row = human_df.loc[idx]\n",
    "    query = str(row[\"text\"]).strip()\n",
    "    input_text = build_input_text(row)\n",
    "\n",
    "    teacher_answer = generate_teacher_answer(query)\n",
    "    if teacher_answer is None:\n",
    "        continue\n",
    "\n",
    "    examples.append({\n",
    "        \"input_text\": input_text,\n",
    "        \"target_text\": teacher_answer,\n",
    "        \"label_source\": \"teacher\",\n",
    "    })\n",
    "\n",
    "print(f\"Total examples after adding teacher labels: {len(examples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778ff2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved distillation dataset to RAG_data\\distillation_dataset.jsonl\n"
     ]
    }
   ],
   "source": [
    "out_df = pd.DataFrame(examples)\n",
    "out_df.to_json(\n",
    "    OUTPUT_KB_JSONL,\n",
    "    orient=\"records\",\n",
    "    lines=True,\n",
    "    force_ascii=False,\n",
    ")\n",
    "print(f\"Saved distillation dataset to {OUTPUT_KB_JSONL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25339447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Label source counts:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label_source'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(preview_df.head(\u001b[32m5\u001b[39m))\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLabel source counts:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpreview_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel_source\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.value_counts())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Cyber_User\\Documents\\GitHub\\Whatsapp_webApp_-Django-\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'label_source'"
     ]
    }
   ],
   "source": [
    "# Looking at the dataset\n",
    "preview_df = pd.read_json(OUTPUT_KB_JSONL, lines=True)\n",
    "print(preview_df.head(5))\n",
    "\n",
    "print(\"\\nLabel source counts:\")\n",
    "print(preview_df[\"label_source\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
